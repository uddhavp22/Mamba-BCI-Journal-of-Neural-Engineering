{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyktttjJkvHepS8m9vu/Xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uddhavp22/Mamba-BCI-Journal-of-Neural-Engineering/blob/main/ATCNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "FW-uETBZ2xpD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qFYTtVv32cYT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# from pytorchtools import EarlyStopping\n",
        "import time\n",
        "#from preprocess import get_data\n",
        "import csv\n",
        "# import sys\n",
        "# sys.path.append('/home/chengxiangxin/mieeg') # 添加模块所在的文件夹路径\n",
        "# import multi_head as mh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "YcztpuOv6JCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False):\n",
        "        super(DepthwiseConv2d, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        # nn.utils.clip_grad_norm_(self.depthwise.parameters(), max_norm=1.0)\n",
        "        return out\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation = 1):\n",
        "        super(CausalConv1d, self).__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation)\n",
        "        nn.init.kaiming_uniform_(self.conv1d.weight, nonlinearity='linear')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, (self.padding, 0))\n",
        "        return self.conv1d(x)\n",
        "\n",
        "\n",
        "class TCN_block(nn.Module):\n",
        "    def __init__(self, depth=2):\n",
        "        super(TCN_block, self).__init__()\n",
        "        self.depth = depth\n",
        "\n",
        "\n",
        "        self.Activation_1 = nn.ELU()\n",
        "        self.TCN_Residual_1 = nn.Sequential(\n",
        "            #可能问题的所在\n",
        "            CausalConv1d(32, 32, 4, dilation=1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            CausalConv1d(32, 32, 4, dilation=1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.TCN_Residual = nn.ModuleList()\n",
        "        self.Activation = nn.ModuleList()\n",
        "        for i in range(depth-1):\n",
        "            TCN_Residual_n = nn.Sequential(\n",
        "            CausalConv1d(32, 32, 4, dilation=2**(i+1)),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            CausalConv1d(32, 32, 4, dilation=2**(i+1)),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "            self.TCN_Residual.append(TCN_Residual_n)\n",
        "            self.Activation.append(nn.ELU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        block = self.TCN_Residual_1(x)\n",
        "        # print(block.shape)\n",
        "        block += x\n",
        "        block = self.Activation_1(block)\n",
        "\n",
        "        for i in range(self.depth-1):\n",
        "            block_o = block\n",
        "            block = self.TCN_Residual[i](block)\n",
        "            block += block_o\n",
        "            # block = torch.add(block_o,block)\n",
        "            block = self.Activation[i](block)\n",
        "        return block\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, input_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = input_size//(2*num_heads)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = self.d_v = input_size // (num_heads * 2)\n",
        "\n",
        "        self.W_Q = nn.Linear(input_size, self.hidden_size * num_heads)\n",
        "        self.W_K = nn.Linear(input_size, self.hidden_size * num_heads)\n",
        "        self.W_V = nn.Linear(input_size, self.hidden_size * num_heads)\n",
        "        self.W_O = nn.Linear(self.hidden_size * num_heads, self.input_size)\n",
        "\n",
        "        nn.init.normal_(self.W_Q.weight, mean=0.0, std=self.d_k ** -0.5)\n",
        "        nn.init.normal_(self.W_K.weight, mean=0.0, std=self.d_k ** -0.5)\n",
        "        nn.init.normal_(self.W_V.weight, mean=0.0, std=self.d_v ** -0.5)\n",
        "        nn.init.normal_(self.W_O.weight, mean=0.0, std=self.d_v ** -0.5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # 计算Q、K、V\n",
        "        Q = self.W_Q(x)   # (batch_size, seq_len, hidden_size * num_heads)\n",
        "        K = self.W_K(x)   # (batch_size, seq_len, hidden_size * num_heads)\n",
        "        V = self.W_V(x)   # (batch_size, seq_len, hidden_size * num_heads)\n",
        "        # print(Q)\n",
        "\n",
        "        # 将Q、K、V按头数进行切分\n",
        "        Q = Q.view(batch_size, seq_len, self.num_heads, self.hidden_size).permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, hidden_size)\n",
        "        K = K.view(batch_size, seq_len, self.num_heads, self.hidden_size).permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, hidden_size)\n",
        "        V = V.view(batch_size, seq_len, self.num_heads, self.hidden_size).permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, hidden_size)\n",
        "        # print('切分',Q)\n",
        "        # 计算注意力分数\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-1, -2)) / (self.hidden_size ** 0.5)   # (batch_size, num_heads, seq_len, seq_len)\n",
        "        attn_scores = attn_scores.softmax(dim=-1)\n",
        "\n",
        "        attn_scores = self.dropout(attn_scores)\n",
        "        # 计算注意力加权后的值\n",
        "        attn_output = torch.matmul(attn_scores, V)   # (batch_size, num_heads, seq_len, hidden_size)\n",
        "        # 将头拼接起来\n",
        "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous().view(batch_size, seq_len, -1)   # (batch_size, seq_len, hidden_size * num_heads)\n",
        "        # 计算输出\n",
        "        output = self.W_O(attn_output)   # (batch_size, seq_len, hidden_size)\n",
        "        return output, attn_scores\n",
        "\n",
        "\n",
        "class attention_block(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(attention_block,self).__init__()\n",
        "        self.LayerNorm = nn.LayerNorm(normalized_shape=32,eps=1e-06)\n",
        "        self.mha = nn.MultiheadAttention(32, 2,dropout=0.5, batch_first=True)\n",
        "        #self.mha = MultiHeadAttention(2,32,0.5)\n",
        "        # self.mha = MultiHeadAttention(32, 2)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #问题\n",
        "        x = x.permute(2, 0, 1)\n",
        "        # x = self.LayerNorm(x)\n",
        "        # att_out,_ = self.mha(x,x,x)\n",
        "        att_out, _ = self.mha(query=x, key=x, value=x)\n",
        "        att_out = self.drop(att_out)\n",
        "        output = att_out.permute(1, 2, 0) + x.permute(1, 2, 0)\n",
        "        return output\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(conv_block,self).__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "                nn.Conv2d(1, 16, kernel_size=(1,64), bias=False,padding='same'),\n",
        "                nn.BatchNorm2d(16),\n",
        "                # problem,\n",
        "            )\n",
        "        self.depthwise = nn.Conv2d(16, 16, (22,1), stride=1, padding=0, dilation=1, groups=16, bias=False)\n",
        "        self.pointwise = nn.Conv2d(16, 16*2, 1, 1, 0, 1, 1, bias=False)\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ELU(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.AvgPool2d(kernel_size=(1,8)),\n",
        "                nn.Conv2d(32, 32, kernel_size=(1,16), bias=False,padding='same'),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ELU(),\n",
        "                nn.AvgPool2d(kernel_size=(1, 7)),\n",
        "                nn.Dropout(0.5),\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block_1(x)\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        out = self.conv_block_2(x)\n",
        "        # nn.utils.clip_grad_norm_(self.depthwise.parameters(), max_norm=1.0)\n",
        "        return out\n",
        "\n",
        "class ATCNet(nn.Module):\n",
        "\n",
        "    def __init__(self, ):\n",
        "        super(ATCNet, self).__init__()\n",
        "        #conv模块\n",
        "        # self.conv_block = nn.Sequential(\n",
        "        #         nn.Conv2d(1, 16, kernel_size=(64,1), bias=False,padding='same'),\n",
        "        #         nn.BatchNorm2d(16),\n",
        "        #         # problem,\n",
        "        #         DepthwiseConv2d(in_channels=16, out_channels=16*2, kernel_size=(1,22), stride=1, padding=0,dilation=1),\n",
        "        #         nn.BatchNorm2d(32),\n",
        "        #         nn.ELU(),\n",
        "        #         nn.Dropout(0.3),\n",
        "        #         nn.AvgPool2d(kernel_size=(8,1)),\n",
        "        #         nn.Conv2d(32, 32, kernel_size=(16,1), bias=False,padding='same'),\n",
        "        #         nn.BatchNorm2d(32),\n",
        "        #         nn.ELU(),\n",
        "        #         nn.AvgPool2d(kernel_size=(7, 1)),\n",
        "        #         nn.Dropout(0.3),\n",
        "        #     )\n",
        "        # 没问题的模块\n",
        "        # self.conv_block = nn.Sequential(\n",
        "        #         nn.Conv2d(1, 16, kernel_size=(1,64), bias=False,padding='same'),\n",
        "        #         nn.BatchNorm2d(16),\n",
        "        #         # problem,\n",
        "        #         DepthwiseConv2d(in_channels=16, out_channels=16*2, kernel_size=(22,1), stride=1, padding=0,dilation=1),\n",
        "        #         nn.BatchNorm2d(32),\n",
        "        #         nn.ELU(),\n",
        "        #         nn.Dropout(0.5),\n",
        "        #         nn.AvgPool2d(kernel_size=(1,8)),\n",
        "        #         nn.Conv2d(32, 32, kernel_size=(1,16), bias=False,padding='same'),\n",
        "        #         nn.BatchNorm2d(32),\n",
        "        #         nn.ELU(),\n",
        "        #         nn.AvgPool2d(kernel_size=(1, 7)),\n",
        "        #         nn.Dropout(0.5),\n",
        "        #     )\n",
        "        self.conv_block = conv_block()\n",
        "        #self-attention input_size,hidden_size,num_head\n",
        "        self.attention_list = nn.ModuleList()\n",
        "        self.TCN_list = nn.ModuleList()\n",
        "        self.slideOut_list = nn.ModuleList()\n",
        "        self.layerNorm_list = nn.ModuleList()\n",
        "        for i in range(5):\n",
        "            self.layerNorm_list.append(nn.LayerNorm(normalized_shape=32,eps=1e-06))\n",
        "            self.attention_list.append(attention_block())\n",
        "            self.TCN_list.append(TCN_block())\n",
        "            self.slideOut_list.append(nn.Linear(32,4))\n",
        "\n",
        "        # self.layerNormalization = nn.LayerNorm(normalized_shape=16,eps=1e-06 )\n",
        "        # self.multihead_attn = attention_block()\n",
        "        # self.TCN_block = TCN_block()\n",
        "        # self.out_1 = nn.Linear(32,4)\n",
        "\n",
        "\n",
        "        self.out_2 = nn.Linear(160,4)\n",
        "        self.cv_out = nn.Linear(640,4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #64,1,22,1125\n",
        "        # x = x.permute(0, 1, 3, 2)\n",
        "        block1 = self.conv_block(x)\n",
        "        #64,32,1,20\n",
        "        # block1 = block1[:,:, -1,:]\n",
        "        block1 = block1.squeeze(2)\n",
        "\n",
        "        # block2 = self.multihead_attn(block1)\n",
        "        # return 1\n",
        "        # block2 = self.TCN_block(block2)\n",
        "\n",
        "        fuse = 'average'\n",
        "        n_windows = 5\n",
        "        sw_concat = []\n",
        "        for i in range(n_windows):\n",
        "            # print(block1.shape)\n",
        "            # print(i)\n",
        "            st = i\n",
        "            end = block1.shape[2]-n_windows+i+1 #在时间窗口上滑动\n",
        "            # print(end)\n",
        "            block2 = block1[:,:, st:end]  #获得时间窗口内的数据\n",
        "\n",
        "\n",
        "            # block2 = self.layerNorm_list[i](block2.permute(0,2,1)).permute(0,2,1)\n",
        "\n",
        "            # Attention_model\n",
        "            # if attention is not None:\n",
        "            # block2 = attention_block(block2)\n",
        "            block2 = self.attention_list[i](block2)\n",
        "\n",
        "            # Temporal convolutional network (TCN)\n",
        "            block3 = self.TCN_list[i](block2)\n",
        "            # Get feature maps of the last sequence\n",
        "            # 64,32,16\n",
        "            block3 = block3[:,:, -1]\n",
        "            # block3 = torch.functional.F.normalize(block3)\n",
        "\n",
        "            # Outputs of sliding window: Average_after_dense or concatenate_then_dense\n",
        "            if(fuse == 'average'):\n",
        "                # block3 = block3.view(block3.size(0), -1)\n",
        "                sw_concat.append(self.slideOut_list[i](block3))\n",
        "            elif(fuse == 'concat'):\n",
        "                if i == 0:\n",
        "                    sw_concat = block3\n",
        "                else:\n",
        "                    sw_concat = torch.cat((sw_concat, block3), axis=1)\n",
        "\n",
        "        if(fuse == 'average'):\n",
        "            if len(sw_concat) > 1: # more than one window\n",
        "                sw_concat = torch.stack(sw_concat).permute(1,0,2)\n",
        "                # print(sw_concat[0])\n",
        "                sw_concat = torch.mean(sw_concat, dim=1)\n",
        "            else: # one window (# windows = 1)\n",
        "                sw_concat = sw_concat[0]\n",
        "        elif(fuse == 'concat'):\n",
        "            sw_concat = self.out_2(sw_concat)\n",
        "\n",
        "        # sw_concat = self.cv_out(block1.view(block1.size(0), -1))\n",
        "\n",
        "        return sw_concat"
      ],
      "metadata": {
        "id": "s8_AZks721x5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing WORKS with random array  \n"
      ],
      "metadata": {
        "id": "iaveyQir6foU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input=torch.randn(1,1,22,1125)\n",
        "model = ATCNet()\n",
        "output = model(input)\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abVBmLMm6eBE",
        "outputId": "58345ee0-d338-418a-da73-1f757b1b2322"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4])\n",
            "tensor([[ 0.0262,  0.1517,  0.0924, -0.4044]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying it wiht EEG data now\n",
        "#to convert all the gdfs to mne raw objects literally just loop through folder and cook:\n",
        "mne.io.read_raw_gdf() #same stuff like edf file\n"
      ],
      "metadata": {
        "id": "KQAN4e1l6oQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}