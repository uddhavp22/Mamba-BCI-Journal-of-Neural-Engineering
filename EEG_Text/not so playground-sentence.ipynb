{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8e3d42-96db-4470-8b0c-1724f5d15dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b738a3-05fb-4ad1-9421-cfda1abb2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mamba_ssm import Mamba\n",
    "# from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import scipy as sp\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from mamba_ssm.modules.block import Block\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from mamba_model import MambaEEG\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a939243-7b29-462c-93d7-54f1ea934d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50b8817-e077-4494-8bb6-3e9af187aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matlab_string(matlab_extracted_object):\n",
    "    \"\"\"\n",
    "    Converts a string loaded from h5py into a python string\n",
    "    :param matlab_extracted_object:     (h5py)  matlab string object\n",
    "    :return:\n",
    "        extracted_string    (str)   translated string\n",
    "    \"\"\"\n",
    "\n",
    "    # print((chr(c) for c in matlab_extracted_object))\n",
    "    extracted_string = u''.join(chr(c) for c in matlab_extracted_object[:].flatten())\n",
    "    # print(extracted_string)\n",
    "    return extracted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9152608e-953c-4668-ae81-7cf5df84310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "start processing ZuCo task2-NR-2.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebda0b9a4c84751b69c2618525ca0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultsYAG_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXAH_NR.mat\n",
      "keys in f: []\n",
      "resultsXLS_NR.mat\n",
      "keys in f: []\n",
      "resultsYRK_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYDR_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYRP_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYFR_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYHS_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXDT_NR.mat\n",
      "keys in f: []\n",
      "resultsXBB_NR.mat\n",
      "keys in f: []\n",
      "resultsYSL_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYTL_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXWS_NR.mat\n",
      "keys in f: []\n",
      "resultsYIS_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYMD_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXBD_NR.mat\n",
      "keys in f: []\n",
      "resultsYFS_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXSS_NR.mat\n",
      "keys in f: []\n",
      "resultsYSD_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYLS_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsXPB_NR.mat\n",
      "keys in f: []\n",
      "resultsXTR_NR.mat\n",
      "keys in f: []\n",
      "resultsXSE_NR.mat\n",
      "keys in f: []\n",
      "resultsYDG_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYAC_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n",
      "resultsYAK_NR.mat\n",
      "keys in f: ['#refs#', 'sentenceData']\n"
     ]
    }
   ],
   "source": [
    "task = \"NR\"\n",
    "\n",
    "rootdir = \"/radraid/spanchavati/eegtotext/zuco-benchmark/data/\"\n",
    "\n",
    "print('##############################')\n",
    "print(f'start processing ZuCo task2-NR-2.0...')\n",
    "\n",
    "dataset_dict = {}\n",
    "\n",
    "for file in tqdm(os.listdir(rootdir)[::-1]):\n",
    "    if file.endswith(task+\".mat\"):\n",
    "        print(file)\n",
    "\n",
    "        file_name = rootdir + file\n",
    "\n",
    "        # print('file name:', file_name)\n",
    "        subject = file_name.split(\"ts\")[1].split(\"_\")[0]\n",
    "        # print('subject: ', subject)\n",
    "\n",
    "        # exclude YMH due to incomplete data because of dyslexia\n",
    "        if subject != 'YMH':\n",
    "            pass\n",
    "\n",
    "        f = h5py.File(file_name,'r')\n",
    "        print('keys in f:', list(f.keys()))\n",
    "        try:\n",
    "            sentence_data = f['sentenceData']\n",
    "            # break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        contents = []\n",
    "        rawEEG = []\n",
    "        for i in range(sentence_data['rawData'].len()):\n",
    "            content = load_matlab_string(f[sentence_data['content'][i][0]])\n",
    "            raweeg = f[sentence_data['rawData'][i][0]]\n",
    "\n",
    "            contents.append(content)\n",
    "            rawEEG.append(np.array(raweeg))\n",
    "\n",
    "        dataset_dict[subject] = {'content': contents, 'eeg': rawEEG}\n",
    "        #     # contents.append(sentence_data['content'])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac92a9a9-495b-49eb-ac3f-e9eb7477155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EEGTextDatasetV2(Dataset):\n",
    "    def __init__(self, data_dict, subject_keys, tokenizer_name='bert-base-uncased', maxlen=15*500, mode='within'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.maxlen = maxlen\n",
    "        self.data = []\n",
    "        self.subject_to_id = {}\n",
    "        self.mode = mode  # 'within', 'cross', or 'zero-shot'\n",
    "        \n",
    "        self.load_data(data_dict, subject_keys)\n",
    "\n",
    "    def load_data(self, data_dict, subject_keys):\n",
    "        for i, key in enumerate(subject_keys):\n",
    "            patient_data = data_dict[key]\n",
    "            sentences = np.array(patient_data['content'])\n",
    "            eeg_data = patient_data['eeg']\n",
    "            \n",
    "            if key not in self.subject_to_id:\n",
    "                self.subject_to_id[key] = len(self.subject_to_id)\n",
    "            subject_id = self.subject_to_id[key]\n",
    "            \n",
    "            mean, std = self.incremental_mean_std(eeg_data)\n",
    "\n",
    "            for sentence, eeg in zip(sentences, eeg_data):\n",
    "                eeg_processed, attention_mask = self.process_eeg(eeg, mean, std)\n",
    "                if eeg_processed is not None:\n",
    "                    self.data.append({\n",
    "                        'sentence': sentence,\n",
    "                        'eeg': eeg_processed,\n",
    "                        'eeg_attention_mask': attention_mask,\n",
    "                        'subject_id': subject_id\n",
    "                    })\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        tokenized = self.tokenizer(item['sentence'], return_tensors='pt', padding='max_length', truncation=True)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': tokenized['input_ids'][0],\n",
    "            'attention_mask': tokenized['attention_mask'][0],\n",
    "            'eeg': torch.nan_to_num(torch.tensor(item['eeg']), posinf=0, neginf=0).float(),\n",
    "            'eeg_attention_mask': torch.tensor(item['eeg_attention_mask']),\n",
    "            'subject_id': torch.tensor(item['subject_id'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def process_eeg(self, eeg_data, mean, std):\n",
    "        \"\"\"\n",
    "        Normalize EEG by computing total channel mean and std.\n",
    "        Right pad EEG with 0s to self.maxlen, throw error if eeg_data is longer than maxlen.\n",
    "        \"\"\"\n",
    "        if eeg_data.shape[0] < 100:\n",
    "            return None, None\n",
    "    \n",
    "        normalized_eeg = (eeg_data - mean) / std\n",
    "        \n",
    "        # Check if EEG data length exceeds maxlen\n",
    "        if normalized_eeg.shape[0] > self.maxlen:\n",
    "            print(f\"EEG data length {normalized_eeg.shape[0]} exceeds maxlen {self.maxlen}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Create attention mask\n",
    "        attention_mask = np.zeros((self.maxlen,))\n",
    "        attention_mask[:normalized_eeg.shape[0]] = 1\n",
    "        \n",
    "        # Right pad EEG data with zeros\n",
    "        padded_eeg = np.zeros((self.maxlen, normalized_eeg.shape[1]))\n",
    "        padded_eeg[:normalized_eeg.shape[0], :] = normalized_eeg\n",
    "        \n",
    "        return padded_eeg, attention_mask\n",
    "    \n",
    "    def incremental_mean_std(self, data_list):\n",
    "        \"\"\"\n",
    "        Calculate mean and standard deviation incrementally for a list of EEG data arrays.\n",
    "        \"\"\"\n",
    "        n_total = 0\n",
    "        mean = 0\n",
    "        M2 = 0\n",
    "        for data in data_list:\n",
    "            n = data.shape[0]\n",
    "            if n < 100:\n",
    "                continue\n",
    "        n_total += n\n",
    "        delta = data - mean\n",
    "        mean += np.nansum(delta, axis=0) / n_total\n",
    "        delta2 = data - mean\n",
    "        M2 += np.nansum(delta * delta2, axis=0)\n",
    "\n",
    "        variance = M2 / (n_total - 1)\n",
    "        std = np.sqrt(variance)\n",
    "        return mean, std\n",
    "\n",
    "def create_data_splits(data_dict, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    all_sentences = set()\n",
    "    for subject_data in data_dict.values():\n",
    "        all_sentences.update(subject_data['content'])\n",
    "    \n",
    "    # Select test (zero-shot) sentences\n",
    "    test_sentences = set(random.sample(all_sentences, int(len(all_sentences) * test_ratio)))\n",
    "    \n",
    "    train_val_data = {subject: {'content': [], 'eeg': []} for subject in data_dict}\n",
    "    test_data = {subject: {'content': [], 'eeg': []} for subject in data_dict}\n",
    "\n",
    "    for subject, subject_data in data_dict.items():\n",
    "        for sentence, eeg in zip(subject_data['content'], subject_data['eeg']):\n",
    "            if sentence in test_sentences:\n",
    "                test_data[subject]['content'].append(sentence)\n",
    "                test_data[subject]['eeg'].append(eeg)\n",
    "                # print(eeg)\n",
    "            else:\n",
    "                train_val_data[subject]['content'].append(sentence)\n",
    "                train_val_data[subject]['eeg'].append(eeg)\n",
    "    \n",
    "    # Split remaining data into train and validation\n",
    "    train_data = {subject: {'content': [], 'eeg': []} for subject in data_dict}\n",
    "    val_data = {subject: {'content': [], 'eeg': []} for subject in data_dict}\n",
    "\n",
    "    for subject, subject_data in train_val_data.items():\n",
    "        n = len(subject_data['content'])\n",
    "        train_idx = int(n * (train_ratio / (train_ratio + val_ratio)))\n",
    "        \n",
    "        train_data[subject]['content'] = subject_data['content'][:train_idx]\n",
    "        train_data[subject]['eeg'] = subject_data['eeg'][:train_idx]\n",
    "        \n",
    "        val_data[subject]['content'] = subject_data['content'][train_idx:]\n",
    "        val_data[subject]['eeg'] = subject_data['eeg'][train_idx:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def create_datasets(data_dict, tokenizer_name, maxlen):\n",
    "    train_data, val_data, test_data = create_data_splits(data_dict)\n",
    "    \n",
    "    # # Within-subject datasets\n",
    "    # train_within = EEGTextDatasetV2(train_data, list(train_data.keys()), tokenizer_name, maxlen, mode='within')\n",
    "    # val_within = EEGTextDatasetV2(val_data, list(val_data.keys()), tokenizer_name, maxlen, mode='within')\n",
    "    \n",
    "    # Cross-subject dataset\n",
    "    train_data = {subject: {'content': train_data[subject]['content'],\n",
    "                          'eeg': train_data[subject]['eeg']}\n",
    "                for subject in train_data.keys()}\n",
    "    val_data = {subject: {'content': val_data[subject]['content'],\n",
    "                          'eeg':val_data[subject]['eeg']} for subject in val_data.keys()}\n",
    "    \n",
    "    train_cross = EEGTextDatasetV2(train_data, list(train_data.keys()), tokenizer_name, maxlen, mode='cross')\n",
    "    val_cross = EEGTextDatasetV2(val_data, list(val_data.keys()), tokenizer_name, maxlen, mode='cross')\n",
    "    \n",
    "    # Test dataset (zero-shot)\n",
    "    test = EEGTextDatasetV2(test_data, list(test_data.keys()), tokenizer_name, maxlen, mode='test')\n",
    "    \n",
    "    return train_cross, val_cross, test # train_within, val_within, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f009bbc2-ad25-465e-b3e6-61f4541c9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f189582-020a-4070-95f1-9df67e058d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = model_name\n",
    "maxlen = 30*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adf4c82-5723-4c32-820e-142119384e85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG data length 16656 exceeds maxlen 15000\n",
      "EEG data length 21004 exceeds maxlen 15000\n",
      "EEG data length 15570 exceeds maxlen 15000\n",
      "EEG data length 15551 exceeds maxlen 15000\n",
      "EEG data length 22214 exceeds maxlen 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1131728/1136260562.py:63: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  normalized_eeg = (eeg_data - mean) / std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG data length 15460 exceeds maxlen 15000\n",
      "EEG data length 15698 exceeds maxlen 15000\n",
      "EEG data length 18436 exceeds maxlen 15000\n",
      "EEG data length 15910 exceeds maxlen 15000\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = create_datasets(dataset_dict, tokenizer_name, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0427742-d497-4125-a530-b5064cbd0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_ds, batch_size=4, shuffle=True,num_workers= 4)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_ds, batch_size = 4, shuffle = False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f24986-5430-4611-818a-42a104a723b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del batch\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00282a83-0f47-4959-8202-690566411ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3cefc7-8f64-4226-a084-229e834e455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/spanchavati/anaconda3/envs/eegtext/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'eeg_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['eeg_encoder'])`.\n",
      "  rank_zero_warn(\n",
      "/raid/spanchavati/anaconda3/envs/eegtext/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'text_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['text_encoder'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoder = HuggingFaceEncoder(model_name, freeze = True)\n",
    "\n",
    "\n",
    "mm = MambaConfig(ssm_cfg = {'layer':'Mamba1'}, d_model = 32, n_layer = 12)\n",
    "\n",
    "ee = EEGEncoder(n_channels = 105, max_length= maxlen, mamba_config=mm, embedding = 'mean', patient_ids = list(train_ds.subject_to_id.values()))\n",
    "\n",
    "\n",
    "\n",
    "model = EEGTextCLIP(\n",
    "    eeg_encoder=ee,\n",
    "    text_encoder=encoder,\n",
    "    text_embedding_dims=768,\n",
    "    projection_dims=256,\n",
    "    dropout=0.1,\n",
    "    temperature=1.0,\n",
    "    weight_decay=1e-6,\n",
    "    head_lr=1e-4,\n",
    "    image_encoder_lr=1e-4,\n",
    "    text_encoder_lr=1e-4,\n",
    "    lr_scheduler_patience=5.0,\n",
    "    lr_scheduler_factor=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775ea16e-f8f8-4214-95e0-37902e37fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define callbacks\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor='val/loss',\n",
    "#     dirpath='checkpoints/',\n",
    "#     filename='eeg-text-clip-{epoch:02d}-{val_loss:.2f}',\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     max_epochs=10,\n",
    "#     accelerator='gpu',\n",
    "#     devices=[0],\n",
    "#     num_sanity_val_steps=10,\n",
    "#     # fast_dev_run=5,\n",
    "#     # callbacks=[checkpoint_callback],\n",
    "#     # log_every_n_steps=1  # Added logging for debugging\n",
    "# )\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30da3d-66d2-4b03-b116-4e556d37dbe3",
   "metadata": {},
   "source": [
    "<!-- # for batch in train_dataloader:\n",
    "#     break -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e6c2ab-571f-42e9-be1d-ae1fa41dd68f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23fdb06-2ee6-4c94-9d5d-f00df3711430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a37c8-69fe-4e4c-9d19-7537c144c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4354085-1ac9-495b-8c1d-4ce091aa4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del batch\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8ba30-bf1c-4440-98f0-07c38868ed20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e18b2486cb4f268d1e6423f4844d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ab1d205b014e9fbf7806b79ca3dad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Initialize tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Get optimizer and scheduler\n",
    "optim_config = model.configure_optimizers()\n",
    "optimizer = optim_config['optimizer']\n",
    "lr_scheduler = optim_config['lr_scheduler']\n",
    "\n",
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Create a tqdm progress bar for epochs\n",
    "epoch_bar = tqdm(range(num_epochs), desc=\"Training\", position=0)\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Create a tqdm progress bar for batches\n",
    "    batch_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch}\", position=1, leave=False)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batch_bar):\n",
    "        batch = {b: batch[b].to(device) for b in batch}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        eeg_embeddings, text_embeddings = model(batch)\n",
    "        loss = model._compute_losses(eeg_embeddings, text_embeddings).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Update batch progress bar\n",
    "        batch_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        })\n",
    "        \n",
    "        # Log training loss\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(train_dataloader) + batch_idx)\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {b: batch[b].to(device) for b in batch}\n",
    "            eeg_embeddings, text_embeddings = model(batch)\n",
    "            loss = model._compute_losses(eeg_embeddings, text_embeddings).mean()\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    \n",
    "    # Log validation loss\n",
    "    writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "    \n",
    "    # Learning rate scheduler step\n",
    "    # lr_scheduler.step(avg_val_loss) #TURNED THIS OFF 7/23!!!\n",
    "    \n",
    "    # Log learning rate\n",
    "    writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    # Update epoch progress bar\n",
    "    epoch_bar.set_postfix({\n",
    "        'train_loss': f\"{avg_train_loss:.4f}\",\n",
    "        'val_loss': f\"{avg_val_loss:.4f}\",\n",
    "        'lr': f\"{optimizer.param_groups[0]['lr']:.2e}\",\n",
    "        'best_val_loss': f\"{best_val_loss:.4f}\"\n",
    "    })\n",
    "\n",
    "# Close tensorboard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5169c-9c19-48af-849f-1aa9478dd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d471a7-e8ea-4939-9cb3-d92158720e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6a8f5-1d0a-487b-98c2-7101deb26b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_sentences(data_dict):\n",
    "    unique_sentences = {}\n",
    "    for key, patient_data in data_dict.items():\n",
    "        for sentence in patient_data['content']:\n",
    "            if sentence not in unique_sentences:\n",
    "                unique_sentences[sentence] = len(unique_sentences)\n",
    "    return unique_sentences\n",
    "\n",
    "def embed_unique_sentences(model, unique_sentences, tokenizer):\n",
    "    model.eval()\n",
    "    sentence_order = list(unique_sentences.keys())\n",
    "    inputs = tokenizer(sentence_order, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.text_encoder(inputs.to(device))\n",
    "        text_embeddings = model.text_proj(text_features.to(device))\n",
    "    return text_embeddings, sentence_order\n",
    "\n",
    "def embed_eeg_data(model, dataloader):\n",
    "    model.eval()\n",
    "    eeg_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {b: batch[b].to(device) for b in batch}\n",
    "            \n",
    "            eeg_embeds, _ = model(batch)\n",
    "            eeg_embeddings.append(eeg_embeds)\n",
    "    eeg_embeddings = torch.cat(eeg_embeddings)\n",
    "    return eeg_embeddings\n",
    "\n",
    "def compute_similarity(embeddings1, embeddings2):\n",
    "    return cosine_similarity(embeddings1.cpu().numpy(), embeddings2.cpu().numpy())\n",
    "\n",
    "def retrieve_closest(similarity_matrix, sentence_order, top_k=5):\n",
    "    closest_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_k]\n",
    "    closest_sentences = [[sentence_order[idx] for idx in row] for row in closest_indices]\n",
    "    return closest_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee73173-05f3-425f-bd1d-fad36a3eefaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_ds, batch_size = 32, shuffle = False, num_workers = 4)\n",
    "\n",
    "unique_sentences = get_unique_sentences(dataset_dict)\n",
    "text_embeddings, sentence_order = embed_unique_sentences(model, unique_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ff024-4226-4a71-ac66-5e62fd8ce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed EEG data\n",
    "train_eeg_embeddings = embed_eeg_data(model, train_dataloader)\n",
    "val_eeg_embeddings = embed_eeg_data(model, val_dataloader)\n",
    "test_eeg_embeddings = embed_eeg_data(model, test_dataloader)\n",
    "\n",
    "\n",
    "# Compute similarities\n",
    "train_similarity_matrix = compute_similarity(train_eeg_embeddings, text_embeddings)\n",
    "val_similarity_matrix = compute_similarity(val_eeg_embeddings, text_embeddings)\n",
    "test_similarity_matrix = compute_similarity(test_eeg_embeddings, text_embeddings)\n",
    "\n",
    "\n",
    "# Retrieve closest matches\n",
    "train_closest_matches = retrieve_closest(train_similarity_matrix, sentence_order)\n",
    "val_closest_matches = retrieve_closest(val_similarity_matrix, sentence_order)\n",
    "test_closest_matches = retrieve_closest(test_similarity_matrix, sentence_order)\n",
    "\n",
    "\n",
    "# Example: print the closest matches for the first EEG embedding in the validation set\n",
    "print(\"Top matches for the first EEG embedding in the validation set:\")\n",
    "for sentence in val_closest_matches[0]:\n",
    "    print(f\"Sentence: {sentence}, Similarity: {val_similarity_matrix[0, unique_sentences[sentence]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456c75e-c892-47b1-bcbc-d1fa7c22ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdaec0f-c313-4a2a-af16-af5ec6ebe8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_order[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26938e3-ec8b-49a7-b759-53cff08a27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 10\n",
    "\n",
    "#Example: print the closest matches for the first EEG embedding in the validation set\n",
    "print(\"Top matches for the first EEG embedding in the validation set:\")\n",
    "for sentence in train_closest_matches[idx]:\n",
    "    print(f\"Sentence: {sentence}, Similarity: {train_similarity_matrix[idx, unique_sentences[sentence]]:.4f}\")\n",
    "\n",
    "\n",
    "tokenizer.decode(train_ds[idx]['input_ids'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dcf7a-f618-416e-8851-6caebd7c0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sentence_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067f0f2-6a17-4dc5-8547-107fe2b22912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105472ef-b999-4944-91cd-41243c278406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72a547-9878-4e38-83a7-0efd82752dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233ed9c-dad4-401e-9635-2bb7105a7a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ac3b1-d9b6-494e-808b-d4ff00149881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
