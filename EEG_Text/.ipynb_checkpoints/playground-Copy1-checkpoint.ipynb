{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8e3d42-96db-4470-8b0c-1724f5d15dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b738a3-05fb-4ad1-9421-cfda1abb2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm import Mamba\n",
    "# from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import scipy as sp\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from mamba_ssm.modules.block import Block\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from mamba_model import MambaEEG\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be09d0-4f00-4335-aa3b-4367c4b825b7",
   "metadata": {},
   "source": [
    "# @TODO SUBJECT SPEFICIC LAYER!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d38ec533-3b91-41a0-912e-9eb4ac25d2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task2-NR-2.0-dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca39541b-17b7-406d-a1ae-9b81438735bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64f0ad-17bb-4a1f-8d7d-aa889786e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = pickle.load(open('dataset/ZuCo/task2-NR-2.0/pickle/task2-NR-2.0-dataset.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b8166-abe7-4829-a5ef-09eee4927b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic['YAG'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e440c41-1e43-4576-885a-f3e02933accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.99931383, 1.66266501, 1.1260891 , 1.09210467, 1.11598217,\n",
       "       1.16841018, 3.06357574, 1.57445288, 1.35179389, 1.15584254,\n",
       "       1.05645442, 2.63251996, 1.66265202, 1.51152825, 1.20166445,\n",
       "       1.15183032, 2.94588852, 1.44206679, 1.14164686, 2.10525537,\n",
       "       1.08507633, 1.03475666, 0.9827835 , 1.16995919, 1.71615124,\n",
       "       1.6393292 , 0.83065325, 0.8150444 , 1.01834726, 1.50741231,\n",
       "       3.38615656, 0.89979148, 0.76764631, 0.80608618, 1.13148689,\n",
       "       3.05741453, 2.91894507, 1.12165987, 1.34454691, 1.18896484,\n",
       "       1.43577671, 1.08912849, 1.27571881, 1.45165181, 1.57095182,\n",
       "       1.70521653, 2.478441  , 1.17878437, 1.39465129, 1.42945838,\n",
       "       1.50007725, 1.53819156, 1.2499299 , 1.34544313, 1.56442928,\n",
       "       1.61160123, 1.46748006, 1.64660895, 1.65201652, 1.5647397 ,\n",
       "       1.77583063, 1.7138586 , 1.79244626, 1.60919929, 1.29906607,\n",
       "       1.14817905, 1.429672  , 2.11905003, 2.20650697, 1.84685791,\n",
       "       1.49745357, 0.8277719 , 0.68556255, 2.10811996, 1.81952858,\n",
       "       1.1564393 , 0.9595592 , 1.11570871, 1.97325814, 1.5424639 ,\n",
       "       1.19482088, 0.98033929, 2.16171217, 1.98576736, 1.29863644,\n",
       "       1.08316994, 1.41445041, 0.83537352, 1.53106511, 1.97344232,\n",
       "       1.47091246, 1.09420431, 0.97307056, 1.10434365, 3.38925862,\n",
       "       2.06197762, 1.25356889, 0.89308351, 1.12209666, 4.57220364,\n",
       "              nan, 2.17232633, 1.10903907, 1.08784044, 1.77556515])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic['YAG'][0]['sentence_level_EEG']['mean_t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "729eeb11-dc35-4f4c-a3ae-b4d317e7da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n",
      "dict_keys(['mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2'])\n"
     ]
    }
   ],
   "source": [
    "for key in pic.keys():\n",
    "    try:\n",
    "        print(pic[key][0]['sentence_level_EEG'].keys())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5986bf7-5064-4177-b0eb-20bf3a5cb5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'sentence_level_EEG', 'word', 'word_tokens_has_fixation', 'word_tokens_with_mask', 'word_tokens_all'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic['YAK'][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7d8ccb5-6949-4675-8fd6-a0b30156a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "encoder = HuggingFaceEncoder(model_name)\n",
    "\n",
    "\n",
    "mm = MambaConfig(ssm_cfg = {'layer':'Mamba1'}, d_model = 64)\n",
    "\n",
    "ee = EEGEncoder(mamba_config=mm, embedding = 'last').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "682bdd35-602e-4bcf-94ed-b5ca711091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand((1,20, 22)).cuda()\n",
    "inputs = tokenizer([\"This is a sentence\"], return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e4ff6f6-3bbc-40bf-9653-6ebab0afd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3947bb31-5018-40de-9ed9-f077872ae2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = EEGTextCLIP(ee, encoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29fddaf-54fb-4841-a3f3-c6f3148f98bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b160868b-4c7e-4c71-9ea8-121e61cc1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(\"This is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29367908-acac-4403-b0c5-775a448e4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1636,  3.0080, -0.1541,  ...,  0.7479, -0.4782, -0.1189]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[-0.0857, -0.5431, -0.4438,  ..., -0.4187, -0.6993,  1.0623]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc(test, inputs.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9aa492-828e-461a-b743-cf0eff329df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[[ 0.0884, -0.1475,  0.1752,  ..., -0.0535, -0.1021,  0.5540]],\n",
      "\n",
      "        [[ 0.1275, -0.2232,  0.1702,  ..., -0.0162,  0.0776,  0.1723]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "model_name = 'bert-base-uncased'\n",
    "encoder = HuggingFaceEncoder(model_name)\n",
    "\n",
    "# For sentences\n",
    "sentences = [\"This is a sentence.\", \"Here is another one.\"]\n",
    "sentence_embeddings = encoder.process_sentences(sentences, pooling='mean')\n",
    "print(\"Sentence embeddings:\", sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a939243-7b29-462c-93d7-54f1ea934d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf63b85-f9f4-4a05-9afa-09f84ca4d808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb19f5-eba5-4fc0-af81-d4e53260a1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
